import feedparser
import re

aptopheadlines = "http://hosted2.ap.org/atom/APDEFAULT/3d281c11a96b4ad082fe88aa0db04305"
apworldfeed = "http://hosted2.ap.org/atom/APDEFAULT/cae69a7523db45408eeb2b3a98c0c9c5"
gasbuddyfeedTH="http://www.gasbuddy.com/GB_Detailed_RSS.aspx?state=IN&area=Terre+Haute"
gasbuddyfeedIndy="http://www.gasbuddy.com/GB_Detailed_RSS.aspx?state=IN&area=Indianapolis+-+central"
gasbuddyfeedUSA = "http://gasbuddy.com/GB_Generic.aspx"


news_feed_urls = [apworldfeed, apworldfeed]
gas_feed_urls = [ gasbuddyfeedTH, gasbuddyfeedIndy, gasbuddyfeedUSA]


def cleanup_GB_feed(data):
    ''' This is specifically tailored for custom GasBuddy feeds '''
    beg= "&nbsp;"
    end = "</td>"
    p = re.compile(r'&nbsp;\d.\d\d</td>')
    return [float(x.lstrip(beg).rstrip(end)) for x in p.findall(data)]

def get_gas_prices():
    feed = feedparser.parse(gasbuddyfeedTH)
    thprices = cleanup_GB_feed(feed['items'][0]['summary'])
    thaverage = sum(thprices) / len(thprices)

    feed = feedparser.parse(gasbuddyfeedIndy)
    indyprices = cleanup_GB_feed(feed['items'][0]['summary'])
    indyaverage = sum(indyprices) / len(indyprices)

    feed = feedparser.parse(gasbuddyfeedUSA)
    summary = filter(lambda f: "Average" in f['title'], feed['items'])[0]['summary']
    nationAverage =  float(re.findall(r'Today</td><td>\$ \d.\d\d', summary)[0][-4:])

    print "Terre Haute"
    print thprices
    print thaverage
    print

    print "Indy"
    print indyprices
    print indyaverage
    print

    print "US Average"
    print nationAverage


    
def main():
    allnewsitems = []

    for url in news_feed_urls:
        feed = feedparser.parse(url)
        allnewsitems.extend(feed['items'])

    get_gas_prices()
    
main()


#for x, y in feed["items"][0].iteritems():
#    print x, y

#for f in feed["items"]:
#    print cleanup_GB_feed(f["title"])
#    print cleanup_GB_feed(f["summary"])
